{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of PIFuHD Demo","provenance":[{"file_id":"11z58bl3meSzo6kFqkahMa35G5jmh2Wgt","timestamp":1611039618075},{"file_id":"1GFSsqP2BWz4gtq0e-nki00ZHSirXwFyY","timestamp":1592100981251},{"file_id":"1fgRNZxFag-YyLOhVke77Non19YiZ6raM","timestamp":1586659114015},{"file_id":"1Z2_uKAAvOtQVrUulcxmP6m9TD-Pegl0r","timestamp":1586656948105},{"file_id":"1MEfpnXIxxbw2tjSRc1hqkxb2HrTToTBn","timestamp":1586052797157}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"eclLG4xlJRIE"},"source":["# PIFuHD Demo: https://shunsukesaito.github.io/PIFuHD/\n","\n","![](https://shunsukesaito.github.io/PIFuHD/resources/images/pifuhd.gif)\n","\n","Made by [![Follow](https://img.shields.io/twitter/follow/psyth91?style=social)](https://twitter.com/psyth91)\n","\n","To see how the model works, visit the project repository.\n","\n","[![GitHub stars](https://img.shields.io/github/stars/facebookresearch/pifuhd?style=social)](https://github.com/facebookresearch/pifuhd)"]},{"cell_type":"markdown","metadata":{"id":"wmFdsTvLKtBO"},"source":["## Note\n","Make sure that your runtime type is 'Python 3 with GPU acceleration'. To do so, go to Edit > Notebook settings > Hardware Accelerator > Select \"GPU\"."]},{"cell_type":"markdown","metadata":{"id":"1TfPAtL4CyZw"},"source":["## More Info\n","- Paper: https://arxiv.org/pdf/2004.00452.pdf\n","- Repo: https://github.com/facebookresearch/pifuhd\n","- Project Page: https://shunsukesaito.github.io/PIFuHD/\n","- 1-minute/5-minute Presentation (see below)"]},{"cell_type":"code","metadata":{"id":"5DDpqpf2BABR","colab":{"base_uri":"https://localhost:8080/","height":928},"executionInfo":{"status":"ok","timestamp":1611133687451,"user_tz":480,"elapsed":892,"user":{"displayName":"Charmve","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj9zT4vUzycNuqCVAvPYhbS-GWoSOslxHjcLtv4=s64","userId":"07530046818488914519"}},"outputId":"2335d946-4ae1-4b9a-a2ce-b4fc318b8e55"},"source":["import IPython\n","IPython.display.HTML('<h2>1-Minute Presentation</h2><iframe width=\"720\" height=\"405\" src=\"https://www.youtube.com/embed/-1XYTmm8HhE\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe><br><h2>5-Minute Presentation</h2><iframe width=\"720\" height=\"405\" src=\"https://www.youtube.com/embed/uEDqCxvF5yc\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>')"],"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/html":["<h2>1-Minute Presentation</h2><iframe width=\"720\" height=\"405\" src=\"https://www.youtube.com/embed/-1XYTmm8HhE\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe><br><h2>5-Minute Presentation</h2><iframe width=\"720\" height=\"405\" src=\"https://www.youtube.com/embed/uEDqCxvF5yc\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"markdown","metadata":{"id":"8vZaAyhUJ9QC"},"source":["## Requirements\n","- Python 3\n","- PyTorch tested on 1.4.0\n","- json\n","- PIL\n","- skimage\n","- tqdm\n","- numpy\n","- cv2"]},{"cell_type":"markdown","metadata":{"id":"sfPDep8LlP_I"},"source":["## Help! I'm new to Google Colab\n","\n","You can check out the following youtube video on how to upload your own picture and run PIFuHD. **Note that with new update, you can upload your own picture more easily with GUI down below.**\n"]},{"cell_type":"code","metadata":{"id":"zaMP1EitljaA","colab":{"base_uri":"https://localhost:8080/","height":425},"executionInfo":{"status":"ok","timestamp":1611133698893,"user_tz":480,"elapsed":1200,"user":{"displayName":"Charmve","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj9zT4vUzycNuqCVAvPYhbS-GWoSOslxHjcLtv4=s64","userId":"07530046818488914519"}},"outputId":"9c38b049-a929-4d23-de62-ecc156c7772a"},"source":["import IPython\n","IPython.display.HTML('<iframe width=\"720\" height=\"405\" src=\"https://www.youtube.com/embed/LWDGR5v3-3o\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>')"],"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/html":["<iframe width=\"720\" height=\"405\" src=\"https://www.youtube.com/embed/LWDGR5v3-3o\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"markdown","metadata":{"id":"WYhlsDkg1Hwb"},"source":["## Clone PIFuHD repository"]},{"cell_type":"code","metadata":{"id":"BmpEwdOd1G1z","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611133702238,"user_tz":480,"elapsed":1410,"user":{"displayName":"Charmve","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj9zT4vUzycNuqCVAvPYhbS-GWoSOslxHjcLtv4=s64","userId":"07530046818488914519"}},"outputId":"5a2ed058-0b66-42f3-f3d7-021fd13630a1"},"source":["!git clone https://github.com/facebookresearch/pifuhd"],"execution_count":23,"outputs":[{"output_type":"stream","text":["Cloning into 'pifuhd'...\n","remote: Enumerating objects: 22, done.\u001b[K\n","remote: Counting objects: 100% (22/22), done.\u001b[K\n","remote: Compressing objects: 100% (21/21), done.\u001b[K\n","remote: Total 213 (delta 7), reused 4 (delta 1), pack-reused 191\u001b[K\n","Receiving objects: 100% (213/213), 407.59 KiB | 21.45 MiB/s, done.\n","Resolving deltas: 100% (100/100), done.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"QvQm-A8ESKb2"},"source":["## Configure input data"]},{"cell_type":"code","metadata":{"id":"xvle9T10fB6g","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611133704787,"user_tz":480,"elapsed":959,"user":{"displayName":"Charmve","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj9zT4vUzycNuqCVAvPYhbS-GWoSOslxHjcLtv4=s64","userId":"07530046818488914519"}},"outputId":"4b5cc2a6-85ab-4144-fb99-6608e5af1b7a"},"source":["cd /content/pifuhd/sample_images"],"execution_count":24,"outputs":[{"output_type":"stream","text":["/content/pifuhd/sample_images\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"9SI7Ye1JfIim"},"source":["**If you want to upload your own picture, run the next cell**. Otherwise, go to the next next cell. Currently PNG, JPEG files are supported."]},{"cell_type":"code","metadata":{"id":"jaV_7Yi8fM-B","colab":{"resources":{"http://localhost:8080/nbextensions/google.colab/files.js":{"data":"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","ok":true,"headers":[["content-type","application/javascript"]],"status":200,"status_text":""}},"base_uri":"https://localhost:8080/","height":75},"executionInfo":{"status":"ok","timestamp":1611133717334,"user_tz":480,"elapsed":9770,"user":{"displayName":"Charmve","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj9zT4vUzycNuqCVAvPYhbS-GWoSOslxHjcLtv4=s64","userId":"07530046818488914519"}},"outputId":"f6ebe112-5c11-4e51-aa80-69fa7e94b888"},"source":["from google.colab import files\n","\n","filename = list(files.upload().keys())[0]"],"execution_count":25,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","     <input type=\"file\" id=\"files-3cafa1bd-f1de-4e5e-a894-7883f6bbc544\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-3cafa1bd-f1de-4e5e-a894-7883f6bbc544\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script src=\"/nbextensions/google.colab/files.js\"></script> "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Saving Diabolik.png to Diabolik (1).png\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"AEzmmB01SOZp"},"source":["import os\n","\n","try:\n","  image_path = '/content/pifuhd/sample_images/%s' % filename\n","except:\n","  image_path = '/content/pifuhd/sample_images/Diabolik.png' # example image\n","image_dir = os.path.dirname(image_path)\n","file_name = os.path.splitext(os.path.basename(image_path))[0]\n","\n","# output pathes\n","obj_path = '/content/pifuhd/results/pifuhd_final/recon/result_%s_256.obj' % file_name\n","out_img_path = '/content/pifuhd/results/pifuhd_final/recon/result_%s_256.png' % file_name\n","video_path = '/content/pifuhd/results/pifuhd_final/recon/result_%s_256.mp4' % file_name\n","video_display_path = '/content/pifuhd/results/pifuhd_final/result_%s_256_display.mp4' % file_name"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"896EC7iQfXkj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611133429030,"user_tz":480,"elapsed":1089,"user":{"displayName":"Charmve","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj9zT4vUzycNuqCVAvPYhbS-GWoSOslxHjcLtv4=s64","userId":"07530046818488914519"}},"outputId":"cfd68bf5-32eb-40d2-fc23-fedf376b5e13"},"source":["cd /content"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"JbVmda9J5TDL"},"source":["## Preprocess (for cropping image)"]},{"cell_type":"code","metadata":{"id":"UtMjWGNU5STe","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611133429996,"user_tz":480,"elapsed":2051,"user":{"displayName":"Charmve","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj9zT4vUzycNuqCVAvPYhbS-GWoSOslxHjcLtv4=s64","userId":"07530046818488914519"}},"outputId":"44e4009b-d616-4d53-dfdc-3d9f9ece4803"},"source":["!git clone https://github.com/Daniil-Osokin/lightweight-human-pose-estimation.pytorch.git"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Cloning into 'lightweight-human-pose-estimation.pytorch'...\n","remote: Enumerating objects: 11, done.\u001b[K\n","remote: Counting objects: 100% (11/11), done.\u001b[K\n","remote: Compressing objects: 100% (8/8), done.\u001b[K\n","remote: Total 115 (delta 3), reused 8 (delta 3), pack-reused 104\u001b[K\n","Receiving objects: 100% (115/115), 227.97 KiB | 11.40 MiB/s, done.\n","Resolving deltas: 100% (46/46), done.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"F-vYklhI5dab","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611133429997,"user_tz":480,"elapsed":2048,"user":{"displayName":"Charmve","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj9zT4vUzycNuqCVAvPYhbS-GWoSOslxHjcLtv4=s64","userId":"07530046818488914519"}},"outputId":"b97044fc-aab3-402c-a82b-3f4b8ae11205"},"source":["cd /content/lightweight-human-pose-estimation.pytorch/"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/lightweight-human-pose-estimation.pytorch\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"dRod9SOu77I6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611133430478,"user_tz":480,"elapsed":2525,"user":{"displayName":"Charmve","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj9zT4vUzycNuqCVAvPYhbS-GWoSOslxHjcLtv4=s64","userId":"07530046818488914519"}},"outputId":"285e1c1a-5477-44bc-bb31-e07f7258ce41"},"source":["!wget https://download.01.org/opencv/openvino_training_extensions/models/human_pose_estimation/checkpoint_iter_370000.pth"],"execution_count":null,"outputs":[{"output_type":"stream","text":["--2021-01-20 09:03:49--  https://download.01.org/opencv/openvino_training_extensions/models/human_pose_estimation/checkpoint_iter_370000.pth\n","Resolving download.01.org (download.01.org)... 23.193.155.164, 2600:1409:12:180::4b21, 2600:1409:12:196::4b21\n","Connecting to download.01.org (download.01.org)|23.193.155.164|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 87959810 (84M) [application/octet-stream]\n","Saving to: ‘checkpoint_iter_370000.pth’\n","\n","checkpoint_iter_370 100%[===================>]  83.88M   226MB/s    in 0.4s    \n","\n","2021-01-20 09:03:49 (226 MB/s) - ‘checkpoint_iter_370000.pth’ saved [87959810/87959810]\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"PdRcDXe38lHB"},"source":["import torch\n","import cv2\n","import numpy as np\n","from models.with_mobilenet import PoseEstimationWithMobileNet\n","from modules.keypoints import extract_keypoints, group_keypoints\n","from modules.load_state import load_state\n","from modules.pose import Pose, track_poses\n","import demo\n","\n","def get_rect(net, images, height_size):\n","    net = net.eval()\n","\n","    stride = 8\n","    upsample_ratio = 4\n","    num_keypoints = Pose.num_kpts\n","    previous_poses = []\n","    delay = 33\n","    for image in images:\n","        rect_path = image.replace('.%s' % (image.split('.')[-1]), '_rect.txt')\n","        img = cv2.imread(image, cv2.IMREAD_COLOR)\n","        orig_img = img.copy()\n","        orig_img = img.copy()\n","        heatmaps, pafs, scale, pad = demo.infer_fast(net, img, height_size, stride, upsample_ratio, cpu=False)\n","\n","        total_keypoints_num = 0\n","        all_keypoints_by_type = []\n","        for kpt_idx in range(num_keypoints):  # 19th for bg\n","            total_keypoints_num += extract_keypoints(heatmaps[:, :, kpt_idx], all_keypoints_by_type, total_keypoints_num)\n","\n","        pose_entries, all_keypoints = group_keypoints(all_keypoints_by_type, pafs)\n","        for kpt_id in range(all_keypoints.shape[0]):\n","            all_keypoints[kpt_id, 0] = (all_keypoints[kpt_id, 0] * stride / upsample_ratio - pad[1]) / scale\n","            all_keypoints[kpt_id, 1] = (all_keypoints[kpt_id, 1] * stride / upsample_ratio - pad[0]) / scale\n","        current_poses = []\n","\n","        rects = []\n","        for n in range(len(pose_entries)):\n","            if len(pose_entries[n]) == 0:\n","                continue\n","            pose_keypoints = np.ones((num_keypoints, 2), dtype=np.int32) * -1\n","            valid_keypoints = []\n","            for kpt_id in range(num_keypoints):\n","                if pose_entries[n][kpt_id] != -1.0:  # keypoint was found\n","                    pose_keypoints[kpt_id, 0] = int(all_keypoints[int(pose_entries[n][kpt_id]), 0])\n","                    pose_keypoints[kpt_id, 1] = int(all_keypoints[int(pose_entries[n][kpt_id]), 1])\n","                    valid_keypoints.append([pose_keypoints[kpt_id, 0], pose_keypoints[kpt_id, 1]])\n","            valid_keypoints = np.array(valid_keypoints)\n","            \n","            if pose_entries[n][10] != -1.0 or pose_entries[n][13] != -1.0:\n","              pmin = valid_keypoints.min(0)\n","              pmax = valid_keypoints.max(0)\n","\n","              center = (0.5 * (pmax[:2] + pmin[:2])).astype(np.int)\n","              radius = int(0.65 * max(pmax[0]-pmin[0], pmax[1]-pmin[1]))\n","            elif pose_entries[n][10] == -1.0 and pose_entries[n][13] == -1.0 and pose_entries[n][8] != -1.0 and pose_entries[n][11] != -1.0:\n","              # if leg is missing, use pelvis to get cropping\n","              center = (0.5 * (pose_keypoints[8] + pose_keypoints[11])).astype(np.int)\n","              radius = int(1.45*np.sqrt(((center[None,:] - valid_keypoints)**2).sum(1)).max(0))\n","              center[1] += int(0.05*radius)\n","            else:\n","              center = np.array([img.shape[1]//2,img.shape[0]//2])\n","              radius = max(img.shape[1]//2,img.shape[0]//2)\n","\n","            x1 = center[0] - radius\n","            y1 = center[1] - radius\n","\n","            rects.append([x1, y1, 2*radius, 2*radius])\n","\n","        np.savetxt(rect_path, np.array(rects), fmt='%d')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"M6cGZD6f6IaY"},"source":["net = PoseEstimationWithMobileNet()\n","checkpoint = torch.load('checkpoint_iter_370000.pth', map_location='cpu')\n","load_state(net, checkpoint)\n","\n","get_rect(net.cuda(), [image_path], 512)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Y0rgMInwTt0s"},"source":["## Download the Pretrained Model"]},{"cell_type":"code","metadata":{"id":"UrIcZweSNRFI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611133445311,"user_tz":480,"elapsed":17350,"user":{"displayName":"Charmve","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj9zT4vUzycNuqCVAvPYhbS-GWoSOslxHjcLtv4=s64","userId":"07530046818488914519"}},"outputId":"0ce3feb7-c5ec-419c-8b04-d964753455f6"},"source":["cd /content/pifuhd/"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/pifuhd\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"k3jjm6HuQRk8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611133460986,"user_tz":480,"elapsed":33022,"user":{"displayName":"Charmve","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj9zT4vUzycNuqCVAvPYhbS-GWoSOslxHjcLtv4=s64","userId":"07530046818488914519"}},"outputId":"620919ea-9743-4a1c-ad4b-bacd4456f4b6"},"source":["!sh ./scripts/download_trained_model.sh"],"execution_count":null,"outputs":[{"output_type":"stream","text":["+ mkdir -p checkpoints\n","+ cd checkpoints\n","+ wget https://dl.fbaipublicfiles.com/pifuhd/checkpoints/pifuhd.pt pifuhd.pt\n","--2021-01-20 09:04:05--  https://dl.fbaipublicfiles.com/pifuhd/checkpoints/pifuhd.pt\n","Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.22.75.142, 104.22.74.142, 172.67.9.4, ...\n","Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.22.75.142|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 1548375177 (1.4G) [application/octet-stream]\n","Saving to: ‘pifuhd.pt’\n","\n","pifuhd.pt           100%[===================>]   1.44G  94.7MB/s    in 15s     \n","\n","2021-01-20 09:04:20 (95.4 MB/s) - ‘pifuhd.pt’ saved [1548375177/1548375177]\n","\n","--2021-01-20 09:04:20--  http://pifuhd.pt/\n","Resolving pifuhd.pt (pifuhd.pt)... failed: Name or service not known.\n","wget: unable to resolve host address ‘pifuhd.pt’\n","FINISHED --2021-01-20 09:04:20--\n","Total wall clock time: 16s\n","Downloaded: 1 files, 1.4G in 15s (95.4 MB/s)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"6heKcA-0QEBw"},"source":["## Run PIFuHD!\n"]},{"cell_type":"code","metadata":{"id":"5995t2PnQTmG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611133483789,"user_tz":480,"elapsed":55821,"user":{"displayName":"Charmve","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj9zT4vUzycNuqCVAvPYhbS-GWoSOslxHjcLtv4=s64","userId":"07530046818488914519"}},"outputId":"8d4fef88-7c5f-41ca-c0b2-250a4b8b6d3d"},"source":["# Warning: all images with the corresponding rectangle files under -i will be processed. \n","!python -m apps.simple_test -r 256 --use_rect -i $image_dir\n","\n","# seems that 256 is the maximum resolution that can fit into Google Colab. \n","# If you want to reconstruct a higher-resolution mesh, please try with your own machine. "],"execution_count":null,"outputs":[{"output_type":"stream","text":["Resuming from  ./checkpoints/pifuhd.pt\n","Warning: opt is overwritten.\n","test data size:  1\n","initialize network with normal\n","initialize network with normal\n","generate mesh (test) ...\n","  0% 0/1 [00:00<?, ?it/s]./results/pifuhd_final/recon/result_Diabolik_256.obj\n","100% 1/1 [00:07<00:00,  7.61s/it]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"EUZ8Nt5rNFXZ"},"source":["## Render the result"]},{"cell_type":"code","metadata":{"id":"5xp5s5uiOiDv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611133494162,"user_tz":480,"elapsed":66190,"user":{"displayName":"Charmve","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj9zT4vUzycNuqCVAvPYhbS-GWoSOslxHjcLtv4=s64","userId":"07530046818488914519"}},"outputId":"c65e7e03-e41f-4a79-d13a-f89b5f832a37"},"source":["!pip install pytorch3d\n","\n","# If you get an error in the next cell, you can instead try the following command (don't forget to comment out the one above!).\n","# Note that this error is caused by inconsistent cuda version for the pytorch3d package and pytorch in Colab environment.\n","# Thus, this issue may persist unless pytorch3d in the pip package is updated with the cuda version consistent with pytorch in Colab.\n","# Also please be aware that the following command is much slower as it builds pytorch3d from scratch.\n","\n","# !pip install 'git+https://github.com/facebookresearch/pytorch3d.git@stable'\n","\n","# You can try another solution below as well. This is also slow and requires you to restart the runtime.\n","\n","# !pip install 'torch==1.6.0+cu101' -f https://download.pytorch.org/whl/torch_stable.html\n","# !pip install 'torchvision==0.7.0+cu101' -f https://download.pytorch.org/whl/torch_stable.html\n","# !pip install 'pytorch3d==0.2.5'"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting pytorch3d\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9c/ae/2350c78cb316c5707eb6d293012a24779d879fc522fc4214bd5d5ecfcb77/pytorch3d-0.3.0-cp36-cp36m-manylinux1_x86_64.whl (30.0MB)\n","\u001b[K     |████████████████████████████████| 30.0MB 86kB/s \n","\u001b[?25hRequirement already satisfied: torchvision>=0.4 in /usr/local/lib/python3.6/dist-packages (from pytorch3d) (0.8.1+cu101)\n","Collecting fvcore\n","  Downloading https://files.pythonhosted.org/packages/d9/fa/80051880c86698764d09a87c0523c43e058047adc060d0590bbd46132c23/fvcore-0.1.2.post20210115.tar.gz\n","Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision>=0.4->pytorch3d) (7.0.0)\n","Requirement already satisfied: torch==1.7.0 in /usr/local/lib/python3.6/dist-packages (from torchvision>=0.4->pytorch3d) (1.7.0+cu101)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision>=0.4->pytorch3d) (1.19.5)\n","Collecting yacs>=0.1.6\n","  Downloading https://files.pythonhosted.org/packages/38/4f/fe9a4d472aa867878ce3bb7efb16654c5d63672b86dc0e6e953a67018433/yacs-0.1.8-py3-none-any.whl\n","Collecting pyyaml>=5.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8a/f2/d2567a720055e0dc09254edd0db810cfdaae01b922fb5bfd6178631b689a/PyYAML-5.4-cp36-cp36m-manylinux1_x86_64.whl (640kB)\n","\u001b[K     |████████████████████████████████| 645kB 45.1MB/s \n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from fvcore->pytorch3d) (4.41.1)\n","Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.6/dist-packages (from fvcore->pytorch3d) (1.1.0)\n","Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from fvcore->pytorch3d) (0.8.7)\n","Collecting iopath>=0.1.2\n","  Downloading https://files.pythonhosted.org/packages/7a/9a/87a281c8cfc0ad1fceb228a4f854d02f19b2c2395476dd573327709b52ae/iopath-0.1.2.tar.gz\n","Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch==1.7.0->torchvision>=0.4->pytorch3d) (0.8)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch==1.7.0->torchvision>=0.4->pytorch3d) (3.7.4.3)\n","Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch==1.7.0->torchvision>=0.4->pytorch3d) (0.16.0)\n","Collecting portalocker\n","  Downloading https://files.pythonhosted.org/packages/89/a6/3814b7107e0788040870e8825eebf214d72166adf656ba7d4bf14759a06a/portalocker-2.0.0-py2.py3-none-any.whl\n","Building wheels for collected packages: fvcore, iopath\n","  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for fvcore: filename=fvcore-0.1.2.post20210115-cp36-none-any.whl size=40892 sha256=61c9c268de40a2aff8d314bfe2ad9ad24117c604d9333304bd7c93a40f2c2a38\n","  Stored in directory: /root/.cache/pip/wheels/cc/0f/bc/fb742771f4a877f1211dd6ed36283b0db9c0ceb2b409b4a039\n","  Building wheel for iopath (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for iopath: filename=iopath-0.1.2-cp36-none-any.whl size=10508 sha256=dcccabbb621afa7abdfcaa99be652b9a8282bcf5fe2d76a8c75d7491bee72d9e\n","  Stored in directory: /root/.cache/pip/wheels/9e/01/e4/1b68f5a2a6b9450ea4246d91840a77e1169f7d4722d76bbc47\n","Successfully built fvcore iopath\n","Installing collected packages: pyyaml, yacs, portalocker, iopath, fvcore, pytorch3d\n","  Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed fvcore-0.1.2.post20210115 iopath-0.1.2 portalocker-2.0.0 pytorch3d-0.3.0 pyyaml-5.4 yacs-0.1.8\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"afwL_-ROCmDf","colab":{"base_uri":"https://localhost:8080/","height":611},"executionInfo":{"status":"error","timestamp":1611133494503,"user_tz":480,"elapsed":66527,"user":{"displayName":"Charmve","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj9zT4vUzycNuqCVAvPYhbS-GWoSOslxHjcLtv4=s64","userId":"07530046818488914519"}},"outputId":"c3905347-8661-4328-df3c-a77bdb75e90a"},"source":["from lib.colab_util import generate_video_from_obj, set_renderer, video\n","\n","renderer = set_renderer()\n","generate_video_from_obj(obj_path, out_img_path, video_path, renderer)\n","\n","# we cannot play a mp4 video generated by cv2\n","!ffmpeg -i $video_path -vcodec libx264 $video_display_path -y -loglevel quiet\n","video(video_display_path)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["** fvcore version of PathManager will be deprecated soon. **\n","** Please migrate to the version in iopath repo. **\n","https://github.com/facebookresearch/iopath \n","\n"],"name":"stderr"},{"output_type":"error","ename":"ImportError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)","\u001b[0;32m<ipython-input-20-22614b7ef849>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab_util\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgenerate_video_from_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_renderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvideo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mrenderer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset_renderer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mgenerate_video_from_obj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_img_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvideo_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/pifuhd/lib/colab_util.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;31m# Util function for loading meshes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpytorch3d\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_objs_as_meshes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHTML\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pytorch3d/io/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mobj_io\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_objs_as_meshes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_obj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mply_io\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_ply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_ply\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pytorch3d/io/obj_io.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpytorch3d\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmtl_io\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_mtl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmake_mesh_texture_atlas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpytorch3d\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_check_faces_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_make_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpytorch3d\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrenderer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTexturesAtlas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTexturesUV\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpytorch3d\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstructures\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMeshes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjoin_meshes_as_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pytorch3d/renderer/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Copyright (c) Facebook, Inc. and its affiliates. All rights reserved.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m from .blending import (\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mBlendParams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mhard_rgb_blend\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pytorch3d/renderer/blending.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# pyre-fixme[21]: Could not find name `_C` in `pytorch3d`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpytorch3d\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_C\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mImportError\u001b[0m: /usr/local/lib/python3.6/dist-packages/pytorch3d/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZN3c104impl23ExcludeDispatchKeyGuardC1ENS_11DispatchKeyE","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"]}]},{"cell_type":"markdown","metadata":{"id":"eUEXAvcvkVYV"},"source":["## Tips for Inputs: My results are broken!\n","\n","(Kudos to those who share results on twitter with [#pifuhd](https://twitter.com/search?q=%23pifuhd&src=recent_search_click&f=live) tag!!!!)\n","\n","Due to the limited variation in the training data, your results might be broken sometimes. Here I share some useful tips to get resonable results. \n","\n","*   Use high-res image. The model is trained with 1024x1024 images. Use at least 512x512 with fine-details. Low-res images and JPEG artifacts may result in unsatisfactory results. \n","*   Use an image with a single person. If the image contain multiple people, reconstruction quality is likely degraded.\n","*   Front facing with standing works best (or with fashion pose)\n","*   The entire body is covered within the image. (Note: now missing legs is partially supported)\n","*   Make sure the input image is well lit. Exteremy dark or bright image and strong shadow often create artifacts.\n","*   I recommend nearly parallel camera angle to the ground. High camera height may result in distorted legs or high heels. \n","*   If the background is cluttered, use less complex background or try removing it using https://www.remove.bg/ before processing.\n","*   It's trained with human only. Anime characters may not work well (To my surprise, indeed many people tried it!!).\n","*   Search on twitter with [#pifuhd](https://twitter.com/search?q=%23pifuhd&src=recent_search_click&f=live) tag to get a better sense of what succeeds and what fails. \n"]},{"cell_type":"markdown","metadata":{"id":"u6U0K5CNAO_u"},"source":["## Share your result! \n","Please share your results with[ #pifuhd](https://twitter.com/search?q=%23pifuhd&src=recent_search_click&f=live) tag on Twitter. Sharing your good/bad results helps and encourages the authors to further push towards producition-quality human digitization at home.\n","**As the tweet buttom below doesn't add the result video automatically, please download the result video above and manually add it to the tweet.**"]},{"cell_type":"code","metadata":{"id":"1CBxbdrM9F-9"},"source":["import IPython\n","IPython.display.HTML('<a href=\"https://twitter.com/intent/tweet?button_hashtag=pifuhd&ref_src=twsrc%5Etfw\" class=\"twitter-hashtag-button\" data-size=\"large\" data-text=\"Google Colab Link: \" data-url=\"https://bit.ly/37sfogZ\" data-show-count=\"false\">Tweet #pifuhd</a><script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>  (Don\\'t forget to add your result to the tweet!)')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2d-1pR8UR7PR"},"source":["## Cool Applications\n","Special thanks to those who play with PIFuHD and came up with many creative applications!! If you made any cool applications, please tweet your demo with [#pifuhd](https://twitter.com/search?q=%23pifuhd&src=recent_search_click&f=live). I'm constantly checking results there.\n","If you need complete texture on the mesh, please try my previous work [PIFu](https://github.com/shunsukesaito/PIFu) as well! It supports 3D reconstruction + texturing from a single image although the geometry quality may not be as good as PIFuHD."]},{"cell_type":"code","metadata":{"id":"68JDAYJFSFMV"},"source":["IPython.display.HTML('<h2>Rigging (Mixamo) + Photoreal Rendering (Blender)</h2><blockquote class=\"twitter-tweet\"><p lang=\"pt\" dir=\"ltr\">vcs ainda tem a PACHORRA de me dizer que eu não sei dançar<a href=\"https://twitter.com/hashtag/b3d?src=hash&amp;ref_src=twsrc%5Etfw\">#b3d</a> <a href=\"https://twitter.com/hashtag/pifuhd?src=hash&amp;ref_src=twsrc%5Etfw\">#pifuhd</a> <a href=\"https://t.co/kHCnLh6zxH\">pic.twitter.com/kHCnLh6zxH</a></p>&mdash; lukas arendero (@lukazvd) <a href=\"https://twitter.com/lukazvd/status/1274810484798128131?ref_src=twsrc%5Etfw\">June 21, 2020</a></blockquote> <script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script><h2>FaceApp + Rigging (Mixamo)</h2><blockquote class=\"twitter-tweet\"><p lang=\"ja\" dir=\"ltr\">カツラかぶってる自分に見える <a href=\"https://twitter.com/hashtag/pifuhd?src=hash&amp;ref_src=twsrc%5Etfw\">#pifuhd</a> <a href=\"https://t.co/V8o7VduTiG\">pic.twitter.com/V8o7VduTiG</a></p>&mdash; Shuhei Tsuchida (@shuhei2306) <a href=\"https://twitter.com/shuhei2306/status/1274507242910314498?ref_src=twsrc%5Etfw\">June 21, 2020</a></blockquote> <script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script><h2>Rigging (Mixamo) + AR (Adobe Aero)</AR><blockquote class=\"twitter-tweet\"><p lang=\"ja\" dir=\"ltr\">写真→PIFuHD→Mixamo→AdobeAeroでサウンド付きARを作成。Zip化してLINEでARコンテンツを共有。<br>写真が1枚あれば簡単にARの3Dアニメーションが作れる時代…凄い。<a href=\"https://twitter.com/hashtag/PIFuHD?src=hash&amp;ref_src=twsrc%5Etfw\">#PIFuHD</a> <a href=\"https://twitter.com/hashtag/AdobeAero?src=hash&amp;ref_src=twsrc%5Etfw\">#AdobeAero</a> <a href=\"https://twitter.com/hashtag/Mixamo?src=hash&amp;ref_src=twsrc%5Etfw\">#Mixamo</a> <a href=\"https://t.co/CbiMi4gZ0K\">pic.twitter.com/CbiMi4gZ0K</a></p>&mdash; モジョン (@mojon1) <a href=\"https://twitter.com/mojon1/status/1273217947872317441?ref_src=twsrc%5Etfw\">June 17, 2020</a></blockquote> <script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script><h2>3D Printing</h2><blockquote class=\"twitter-tweet\"><p lang=\"ja\" dir=\"ltr\"><a href=\"https://twitter.com/hashtag/pifuhd?src=hash&amp;ref_src=twsrc%5Etfw\">#pifuhd</a> 楽しい〜<br>小さい自分プリントした <a href=\"https://t.co/4qyWuij0Hs\">pic.twitter.com/4qyWuij0Hs</a></p>&mdash; isb (@vxzxzxzxv) <a href=\"https://twitter.com/vxzxzxzxv/status/1273136266406694913?ref_src=twsrc%5Etfw\">June 17, 2020</a></blockquote> <script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lX5CTTW_KWhQ"},"source":[""],"execution_count":null,"outputs":[]}]}
<p align="left">
  <a href="https://github.com/Charmve"><img src="https://img.shields.io/badge/GitHub-@Charmve-000000.svg?logo=GitHub" alt="GitHub" target="_blank"></a>
  <a href="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9tbWJpei5xcGljLmNuL21tYml6X3BuZy9aTmRoV05pYjNJUkIzZk5ldWVGZEQ4YnZ4cXlzbXRtRktUTGdFSXZOMUdnTHhDNXV0Y1VBZVJ0T0lJa0hTZTVnVGowamVtZUVOQTJJMHhiU0xjQ3VrVVEvNjQw?x-oss-process=image/format,png" target="_blank" ><img src="https://img.shields.io/badge/å…¬ä¼—å·-@è¿ˆå¾®AIç ”ä¹ ç¤¾-000000.svg?style=flat-square&amp;logo=WeChat" alt="å¾®ä¿¡å…¬ä¼—å·"/></a>
  <a href="https://www.zhihu.com/people/MaiweiE-com" target="_blank" ><img src="https://img.shields.io/badge/%E7%9F%A5%E4%B9%8E-@Charmve-000000.svg?style=flat-square&amp;logo=Zhihu" alt="çŸ¥ä¹"/></a>
  <a href="https://space.bilibili.com/62079686" target="_blank"><img src="https://img.shields.io/badge/Bç«™-@Charmve-000000.svg?style=flat-square&amp;logo=Bilibili" alt="Bç«™"/></a>
  <a href="https://blog.csdn.net/Charmve" target="_blank"><img src="https://img.shields.io/badge/CSDN-@Charmve-000000.svg?style=flat-square&amp;logo=CSDN" alt="CSDN"/></a>
</p>

# ç¬¬ 15 ç«  è¿ç§»å­¦ä¹ 

ä½œè€…: å¼ ä¼Ÿ (Charmve)

æ—¥æœŸ: 2021/05/22

## ç›®å½•

  - ç¬¬ 15 ç«  [è¿ç§»å­¦ä¹ ](chapter15_è¿ç§»å­¦ä¹ æ¦‚è¿°.md)
    - [15.1 æ¦‚è¿°](chapter15_è¿ç§»å­¦ä¹ æ¦‚è¿°.md#151-è¿ç§»å­¦ä¹ æ¦‚è¿°)
      - [15.1.1 èƒŒæ™¯](chapter15_è¿ç§»å­¦ä¹ æ¦‚è¿°.md#1511-èƒŒæ™¯)
      - [15.1.2 å®šä¹‰åŠåˆ†ç±»](chapter15_è¿ç§»å­¦ä¹ æ¦‚è¿°.md#1512-å®šä¹‰åŠåˆ†ç±»)
      - [15.1.3 å…³é”®ç‚¹](chapter15_è¿ç§»å­¦ä¹ æ¦‚è¿°.md#1513-å…³é”®ç‚¹)
    - [15.2 åŸºäºå®ä¾‹çš„è¿ç§»](chapter15_è¿ç§»å­¦ä¹ æ¦‚è¿°.md#152-åŸºäºå®ä¾‹çš„è¿ç§»)
    - [15.3 åŸºäºç‰¹å¾çš„è¿ç§»](chapter15_è¿ç§»å­¦ä¹ æ¦‚è¿°.md#153-åŸºäºç‰¹å¾çš„è¿ç§»)
    - [15.4 åŸºäºå…±äº«å‚æ•°çš„è¿ç§»](chapter15_è¿ç§»å­¦ä¹ æ¦‚è¿°.md#154-åŸºäºå…±äº«å‚æ•°çš„è¿ç§»)
    - [15.5 æ·±åº¦å­¦ä¹ å’Œè¿ç§»å­¦ä¹ ç»“åˆ](chapter15_è¿ç§»å­¦ä¹ æ¦‚è¿°.md#155-æ·±åº¦å­¦ä¹ å’Œè¿ç§»å­¦ä¹ ç»“åˆ)
    - [15.7 å®æˆ˜é¡¹ç›® 2 - èš‚èšå’Œèœœèœ‚çš„åˆ†ç±»é—®é¢˜](chapter15_è¿ç§»å­¦ä¹ çš„åº”ç”¨.md)
      - [15.7.1 è¿ç§»å­¦ä¹ åœ¨è®¡ç®—æœºè§†è§‰é¢†åŸŸçš„åº”ç”¨](#1571-è¿ç§»å­¦ä¹ åœ¨è®¡ç®—æœºè§†è§‰é¢†åŸŸçš„åº”ç”¨)
        - [15.7.1.1 ä¸ºä½•ç”¨è¿ç§»å­¦ä¹ ](#15711-ä¸ºä½•ç”¨è¿ç§»å­¦ä¹ )
        - [15.7.1.2 è¿ç§»å­¦ä¹ çš„ä¼˜ç‚¹](#15712-è¿ç§»å­¦ä¹ çš„ä¼˜ç‚¹)
        - [15.7.1.3 è¿ç§»å­¦ä¹ çš„æ–¹æ³•](#15713-è¿ç§»å­¦ä¹ çš„æ–¹æ³•)
        - [15.7.1.4 è¿ç§»æ–¹æ³•çš„é€‰æ‹©](#15714-è¿ç§»æ–¹æ³•çš„é€‰æ‹©)
      - [15.7.2 å®æˆ˜é¡¹ç›®: èš‚èšå’Œèœœèœ‚çš„åˆ†ç±»é—®é¢˜](#1572-å®æˆ˜é¡¹ç›®-èš‚èšå’Œèœœèœ‚çš„åˆ†ç±»é—®é¢˜)
        - [å®Œæ•´ä»£ç ](#å®Œæ•´ä»£ç )
    - [å°ç»“](#å°ç»“)
    - [å‚è€ƒæ–‡çŒ®](#å‚è€ƒæ–‡çŒ®)

<br>

# 15.7 å®æˆ˜é¡¹ç›® 2 - èš‚èšå’Œèœœèœ‚çš„åˆ†ç±»é—®é¢˜

<p align="center"><a target="_blank" href="colab.research.google.com/github/Charmve/computer-vision-in-action/blob/master/notebooks/17_TL-ants-bees-classification.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" align="center"></a>
</p>

## 15.7.1 è¿ç§»å­¦ä¹ åœ¨è®¡ç®—æœºè§†è§‰é¢†åŸŸçš„åº”ç”¨

### 15.7.1.1 ä¸ºä½•ç”¨è¿ç§»å­¦ä¹ 
å®é™…ä¸Šï¼Œå¾ˆå°‘æœ‰äººä»å¤´å¼€å§‹è®­ç»ƒæ•´ä¸ªå·ç§¯ç½‘ç»œï¼ˆä½¿ç”¨éšæœºåˆå§‹åŒ–ï¼‰ï¼Œå› ä¸ºæ‹¥æœ‰è¶³å¤Ÿå¤§å°çš„æ•°æ®é›†ç›¸å¯¹å¾ˆå°‘ã€‚ ç›¸åï¼Œæˆ‘ä»¬é€šå¸¸åœ¨éå¸¸å¤§çš„æ•°æ®é›†ä¸Šå¯¹ConvNetè¿›è¡Œé¢„è®­ç»ƒï¼ˆä¾‹å¦‚ImageNetï¼Œå…¶ä¸­åŒ…å«1000ä¸ªç±»åˆ«å…±è®¡120ä¸‡å¼ å›¾åƒï¼‰ï¼Œç„¶åå°†ConvNetç”¨ä½œåˆå§‹åŒ–æˆ–å›ºå®šç‰¹å¾æå–å™¨ä»¥å®Œæˆæ„Ÿå…´è¶£çš„ä»»åŠ¡ã€‚

### 15.7.1.2 è¿ç§»å­¦ä¹ çš„ä¼˜ç‚¹
è¿ç§»å­¦ä¹ ä¸»è¦æœ‰ä»¥ä¸‹ä¸‰ä¸ªä¼˜ç‚¹ï¼š

- æ›´é«˜çš„èµ·ç‚¹ã€‚å¾®è°ƒå‰ï¼Œæºæ¨¡å‹çš„åˆå§‹æ€§èƒ½æ¯”ä¸ä½¿ç”¨è¿ç§»å­¦ä¹ é«˜ã€‚
- æ›´é«˜çš„æ–œç‡ã€‚è®­ç»ƒä¸­ï¼Œæºæ¨¡å‹çš„æå‡é€Ÿç‡æ¯”ä¸ä½¿ç”¨è¿ç§»å­¦ä¹ é«˜ã€‚
- æ›´é«˜çš„æ¸è¿›ã€‚è®­ç»ƒå¾—åˆ°çš„æ¨¡å‹çš„æ”¶æ•›æ€§æ¯”ä¸ä½¿ç”¨è¿ç§»å­¦ä¹ æ›´å¥½ã€‚

### 15.7.1.3 è¿ç§»å­¦ä¹ çš„æ–¹æ³•
å®ç°è¿ç§»å­¦ä¹ ä¸»è¦æœ‰ä¸¤ç§å¸¸è§çš„æ–¹æ³•ï¼š

- **Convnetå¾®è°ƒ**ï¼šä»£æ›¿éšæœºåˆå§‹åŒ–ï¼Œæˆ‘ä»¬ä½¿ç”¨é¢„è®­ç»ƒçš„ç½‘ç»œåˆå§‹åŒ–æˆ‘ä»¬çš„æ¨¡å‹ï¼Œä¾‹å¦‚åœ¨imagenet 1000æ•°æ®é›†ä¸Šè®­ç»ƒçš„ç½‘ç»œã€‚å…¶ä½™çš„è®­ç»ƒæ–¹æ³•è¿˜æ˜¯ç…§æ—§ã€‚
- **Convnetä½œä¸ºå›ºå®šçš„ç‰¹å¾æå–å™¨**ï¼šå†»ç»“é™¤å…¨è¿æ¥å±‚å¤–çš„æ‰€æœ‰ç½‘ç»œçš„æƒé‡ï¼Œæœ€åçš„å…¨è¿æ¥å±‚ç”¨ä¸€ä¸ªå…·æœ‰éšæœºæƒé‡çš„æ–°å±‚æ¥æ›¿æ¢ï¼Œå¹¶ä¸”ä»…è®­ç»ƒè¯¥å±‚ã€‚
æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬å°†è¿™ä¸¤ç§æ–¹æ³•åˆ†åˆ«ç®€ç§°ä¸ºï¼šå‚æ•°å¾®è°ƒå’Œç‰¹å¾æå–ã€‚

### 15.7.1.4 è¿ç§»æ–¹æ³•çš„é€‰æ‹©

|æ•°æ®é›†å¤§å°	|å’Œé¢„è®­ç»ƒæ¨¡å‹ä½¿ç”¨æ•°æ®é›†çš„ç›¸ä¼¼åº¦|	ä¸€èˆ¬é€‰æ‹©|
|:--:|:--:|:--|
|å°	|é«˜	|ç‰¹å¾æå–|
|å¤§	|é«˜	|å‚æ•°å¾®è°ƒ|
|å°	|ä½	|ç‰¹å¾æå–+SVM|
|å¤§	|ä½	|ä»å¤´è®­ç»ƒæˆ–å‚æ•°å¾®è°ƒï¼ˆæ¨èï¼‰|

## 15.7.2 å®æˆ˜é¡¹ç›®: èš‚èšå’Œèœœèœ‚çš„åˆ†ç±»é—®é¢˜

ä»Šå¤©æˆ‘ä»¬è¦è§£å†³çš„é—®é¢˜æ˜¯é€šè¿‡è¿ç§»å­¦ä¹ è®­ç»ƒä¸€ä¸ªæ¨¡å‹æ¥å®ç°èš‚èšå’Œèœœèœ‚çš„åˆ†ç±»ã€‚å¦‚æœä»å¤´å¼€å§‹è®­ç»ƒçš„è¯ï¼Œè¿™æ˜¯ä¸€ä¸ªéå¸¸å°çš„æ•°æ®é›†ï¼Œå°±ç®—åšäº†æ•°æ®å¢å¼ºä¹Ÿéš¾ä»¥è¾¾åˆ°å¾ˆå¥½çš„æ•ˆæœã€‚å› æ­¤æˆ‘ä»¬å¼•å…¥è¿ç§»å­¦ä¹ çš„æ–¹æ³•ï¼Œé‡‡ç”¨åœ¨ ImageNet ä¸Šè®­ç»ƒè¿‡çš„ resnet18 ä½œä¸ºæˆ‘ä»¬çš„é¢„è®­ç»ƒæ¨¡å‹ã€‚

### 15.7.2.1 ä¸‹è½½æ•°æ®

> - æ¨èï¼šhttps://download.csdn.net/download/qq_42951560/13201074
> - å¤‡ç”¨ï¼šhttps://ghgxj.lanzous.com/i9EGHiv97za

imagenetæ•°æ®é›†ä¸‰é€šé“çš„å‡å€¼å’Œæ ‡å‡†å·®åˆ†åˆ«æ˜¯ï¼š$[0.485, 0.456, 0.406]ï¼Œ[0.229, 0.224, 0.225]$ã€‚

è¯¥æ•°æ®é›†æ˜¯imagenetéå¸¸å°çš„ä¸€ä¸ªå­é›†ã€‚åªåŒ…å«èš‚èšå’Œèœœèœ‚ä¸¤ç±»ã€‚

æ‰€ä»¥æ•°æ®æ ‡å‡†åŒ–Normalizeçš„æ—¶å€™æˆ‘ä»¬ä¹Ÿç»§æ‰¿ä½¿ç”¨imagenetçš„å‡å€¼å’Œæ ‡å‡†å·®ã€‚

|ç§ç±»	|è®­ç»ƒé›†	|éªŒè¯é›†|
|--|--|--|
|èš‚èš|	123|	70|
|èœœèœ‚|	121|	83|
|æ€»è®¡|	244|	153|


### å¯¼å…¥æ¨¡å—

```python
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from torch.optim import lr_scheduler
import torchvision
from torchvision import datasets, models, transforms
import numpy as np
import matplotlib.pyplot as plt
import os
import time
import copy
```

### æ•°æ®å¢å¼º
```python
data_transforms = {
    'train': transforms.Compose([
        transforms.RandomResizedCrop(224),
        transforms.RandomHorizontalFlip(),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ]),
    'val': transforms.Compose([
        transforms.Resize(256),
        transforms.CenterCrop(224),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ])
}
```

### åˆ¶ä½œæ•°æ®é›†

```python
image_datasets = {
    x: datasets.ImageFolder(
        root=os.path.join('./dataset', x),
        transform=data_transforms[x]
    ) for x in ['train', 'val']
}
```

### æ•°æ®åŠ è½½å™¨
```python
dataloaders = {
    x: DataLoader(
        dataset=image_datasets[x],
        batch_size=4,
        shuffle=True,
        num_workers=0
    ) for x in ['train', 'val']
}
```

### ç›¸å…³ä¿¡æ¯çš„æ‰“å°
```python
dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}
class_names = image_datasets['train'].classes
device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')
'''è¾“å‡º
{'train': 244, 'val': 153}
['ants', 'bees']
device(type='cuda', index=0)
'''
```
è¯´æ˜: 
- dataset_sizesï¼šæ•°æ®é›†å¤§å°ï¼›è®­ç»ƒé›†244å¼ å›¾ç‰‡ï¼ŒéªŒè¯é›†153å¼ å›¾ç‰‡ã€‚
- class_namesï¼šç±»åï¼›å°±ä¸¤ç±»ï¼Œantså’Œbeesã€‚
- deviceï¼šè®­ç»ƒè®¾å¤‡ï¼›å¦‚æœæœ‰GPUå°±ä½¿ç”¨GPUï¼Œæ²¡æœ‰å°±ç”¨CPUï¼Œä¸è¿‡GPUè®­ç»ƒè¦å¿«å¾ˆå¤šå€ã€‚

### è®­ç»ƒæ•°æ®å¯è§†åŒ–
```python
inputs, labels = next(iter(dataloaders['train']))
grid_images = torchvision.utils.make_grid(inputs)

def no_normalize(im):
    im = im.permute(1, 2, 0)
    im = im*torch.Tensor([0.229, 0.224, 0.225])+torch.Tensor([0.485, 0.456, 0.406])
    return im

grid_images = no_normalize(grid_images)
plt.title([class_names[x] for x in labels])
plt.imshow(grid_images)
plt.show()
```

![image](https://user-images.githubusercontent.com/29084184/119220095-4d47e300-bb1b-11eb-8720-441d03c2603d.png)


### è®­ç»ƒæ¨¡å‹
ä¹‹å‰æåˆ°è¿‡ï¼Œè¿ç§»å­¦ä¹ æœ‰ä¸¤ç§å¸¸è§çš„æ–¹æ³•ï¼Œæˆ‘ä»¬å°±ç®€å•çš„ç§°ä¹‹ä¸ºå‚æ•°å¾®è°ƒå’Œç‰¹å¾æå–å§ã€‚ä¸‹é¢ï¼Œæˆ‘ä»¬å°†åˆ†åˆ«ä½¿ç”¨è¿™ä¸¤ç§æ–¹æ³•æ¥è®­ç»ƒæˆ‘ä»¬çš„æ¨¡å‹ï¼Œæœ€åå†è¿›è¡Œå¯¹æ¯”åˆ†æã€‚ä¸¤ç§æ–¹æ³•ç”¨åŒä¸€ä¸ªå‡½æ•°è®­ç»ƒï¼Œåªä¸è¿‡ä¼ çš„å‚æ•°ä¸åŒã€‚å…¬ç”¨çš„è®­ç»ƒå‡½æ•°å¦‚ä¸‹ï¼š

```python
def train_model(model, criterion, optimizer, scheduler, num_epochs=10):
    t1 = time.time()

    best_model_wts = copy.deepcopy(model.state_dict())
    best_acc = 0.0

    for epoch in range(num_epochs):
        lr = optimizer.param_groups[0]['lr']
        print(
            f'EPOCH: {epoch+1:0>{len(str(num_epochs))}}/{num_epochs}',
            f'LR: {lr:.4f}',
            end=' '
        )
        # æ¯è½®éƒ½éœ€è¦è®­ç»ƒå’Œè¯„ä¼°
        for phase in ['train', 'val']:
            if phase == 'train':
                model.train()  # å°†æ¨¡å‹è®¾ç½®ä¸ºè®­ç»ƒæ¨¡å¼
            else:
                model.eval()   # å°†æ¨¡å‹è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼

            running_loss = 0.0
            running_corrects = 0

            # éå†æ•°æ®
            for inputs, labels in dataloaders[phase]:
                inputs = inputs.to(device)
                labels = labels.to(device)

                # æ¢¯åº¦å½’é›¶
                optimizer.zero_grad()

                # å‰å‘ä¼ æ’­
                with torch.set_grad_enabled(phase == 'train'):
                    outputs = model(inputs)
                    preds = outputs.argmax(1)
                    loss = criterion(outputs, labels)

                    # åå‘ä¼ æ’­+å‚æ•°æ›´æ–°
                    if phase == 'train':
                        loss.backward()
                        optimizer.step()

                # ç»Ÿè®¡
                running_loss += loss.item() * inputs.size(0)
                running_corrects += (preds == labels.data).sum()
            if phase == 'train':
                # è°ƒæ•´å­¦ä¹ ç‡
                scheduler.step()

            epoch_loss = running_loss / dataset_sizes[phase]
            epoch_acc = running_corrects.double() / dataset_sizes[phase]

            # æ‰“å°è®­ç»ƒè¿‡ç¨‹
            if phase == 'train':
                print(
                    f'LOSS: {epoch_loss:.4f}',
                    f'ACC: {epoch_acc:.4f} ',
                    end=' '
                )
            else:
                print(
                    f'VAL-LOSS: {epoch_loss:.4f}',
                    f'VAL-ACC: {epoch_acc:.4f} ',
                    end='\n'
                )

            # æ·±åº¦æ‹·è´æ¨¡å‹å‚æ•°
            if phase == 'val' and epoch_acc > best_acc:
                best_acc = epoch_acc
                best_model_wts = copy.deepcopy(model.state_dict())

    t2 = time.time()
    total_time = t2-t1
    print('-'*10)
    print(
        f'TOTAL-TIME: {total_time//60:.0f}m{total_time%60:.0f}s',
        f'BEST-VAL-ACC: {best_acc:.4f}'
    )
    # åŠ è½½æœ€ä½³çš„æ¨¡å‹æƒé‡
    model.load_state_dict(best_model_wts)
    return model
```

#### å‚æ•°å¾®è°ƒçš„æ–¹æ³•

è¯¥æ–¹æ³•ä½¿ç”¨é¢„è®­ç»ƒçš„å‚æ•°æ¥åˆå§‹åŒ–æˆ‘ä»¬çš„ç½‘ç»œæ¨¡å‹ï¼Œä¿®æ”¹å…¨è¿æ¥å±‚åå†è®­ç»ƒæ‰€æœ‰å±‚ã€‚

```python
# åŠ è½½é¢„è®­ç»ƒæ¨¡å‹
model_ft = models.resnet18(pretrained=True)

# è·å–resnet18çš„å…¨è¿æ¥å±‚çš„è¾“å…¥ç‰¹å¾æ•°
num_ftrs = model_ft.fc.in_features

# è°ƒæ•´å…¨è¿æ¥å±‚çš„è¾“å‡ºç‰¹å¾æ•°ä¸º2
model_ft.fc = nn.Linear(num_ftrs, len(class_names))

# å°†æ¨¡å‹æ”¾åˆ°GPU/CPU
model_ft = model_ft.to(device)

# å®šä¹‰æŸå¤±å‡½æ•°
criterion = nn.CrossEntropyLoss()

# é€‰æ‹©ä¼˜åŒ–å™¨
optimizer_ft = optim.SGD(model_ft.parameters(), lr=1e-3, momentum=0.9)

# å®šä¹‰ä¼˜åŒ–å™¨å™¨è°ƒæ•´ç­–ç•¥ï¼Œæ¯5è½®åå­¦ä¹ ç‡ä¸‹è°ƒ0.1ä¸ªä¹˜æ³•å› å­
exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=5, gamma=0.1)

# è°ƒç”¨è®­ç»ƒå‡½æ•°è®­ç»ƒ
model_ft = train_model(
    model_ft, 
    criterion, 
    optimizer_ft, 
    exp_lr_scheduler,
    num_epochs=10
)
```

#### ç‰¹å¾æå–çš„æ–¹æ³•
è¯¥æ–¹æ³•å†»ç»“é™¤å…¨è¿æ¥å±‚å¤–çš„æ‰€æœ‰å±‚çš„æƒé‡ï¼Œä¿®æ”¹å…¨è¿æ¥å±‚åä»…è®­ç»ƒå…¨è¿æ¥å±‚ã€‚

```python
# åŠ è½½é¢„è®­ç»ƒæ¨¡å‹
model_conv = models.resnet18(pretrained=True)

# å†»ç»“é™¤å…¨è¿æ¥å±‚å¤–çš„æ‰€æœ‰å±‚, ä½¿å…¶æ¢¯åº¦ä¸ä¼šåœ¨åå‘ä¼ æ’­ä¸­è®¡ç®—
for param in model_conv.parameters():
    param.requires_grad = False

# è·å–resnet18çš„å…¨è¿æ¥å±‚çš„è¾“å…¥ç‰¹å¾æ•°
num_ftrs = model_conv.fc.in_features

# è°ƒæ•´å…¨è¿æ¥å±‚çš„è¾“å‡ºç‰¹å¾æ•°ä¸º2
model_conv.fc = nn.Linear(num_ftrs, 2)

# å°†æ¨¡å‹æ”¾åˆ°GPU/CPU
model_conv = model_conv.to(device)

# å®šä¹‰æŸå¤±å‡½æ•°
criterion = nn.CrossEntropyLoss()

# é€‰æ‹©ä¼˜åŒ–å™¨, åªä¼ å…¨è¿æ¥å±‚çš„å‚æ•°
optimizer_conv = optim.SGD(model_conv.fc.parameters(), lr=1e-3, momentum=0.9)

# å®šä¹‰ä¼˜åŒ–å™¨å™¨è°ƒæ•´ç­–ç•¥ï¼Œæ¯5è½®åå­¦ä¹ ç‡ä¸‹è°ƒ0.1ä¸ªä¹˜æ³•å› å­
exp_lr_scheduler = lr_scheduler.StepLR(optimizer_conv, step_size=5, gamma=0.1)

# è°ƒç”¨è®­ç»ƒå‡½æ•°è®­ç»ƒ
model_conv = train_model(
    model_conv,
    criterion,
    optimizer_conv,
    exp_lr_scheduler,
    num_epochs=10
)
```

### ä¸¤ç§æ–¹æ³•çš„å¯¹æ¯”
- å‚æ•°å¾®è°ƒ

```shell
EPOCH: 01/10 LR: 0.0010 LOSS: 0.8586 ACC: 0.5902  VAL-LOSS: 0.2560 VAL-ACC: 0.9020
EPOCH: 02/10 LR: 0.0010 LOSS: 1.1052 ACC: 0.6803  VAL-LOSS: 0.3033 VAL-ACC: 0.8758
EPOCH: 03/10 LR: 0.0010 LOSS: 0.6706 ACC: 0.7910  VAL-LOSS: 0.9216 VAL-ACC: 0.8039
EPOCH: 04/10 LR: 0.0010 LOSS: 0.7949 ACC: 0.7623  VAL-LOSS: 0.2686 VAL-ACC: 0.8954
EPOCH: 05/10 LR: 0.0010 LOSS: 0.5725 ACC: 0.7500  VAL-LOSS: 0.3638 VAL-ACC: 0.8431
EPOCH: 06/10 LR: 0.0001 LOSS: 0.3003 ACC: 0.8525  VAL-LOSS: 0.2749 VAL-ACC: 0.8758
EPOCH: 07/10 LR: 0.0001 LOSS: 0.4123 ACC: 0.8197  VAL-LOSS: 0.2747 VAL-ACC: 0.8889
EPOCH: 08/10 LR: 0.0001 LOSS: 0.3650 ACC: 0.8361  VAL-LOSS: 0.2942 VAL-ACC: 0.8758
EPOCH: 09/10 LR: 0.0001 LOSS: 0.3748 ACC: 0.8279  VAL-LOSS: 0.2560 VAL-ACC: 0.9020
EPOCH: 10/10 LR: 0.0001 LOSS: 0.3523 ACC: 0.8361  VAL-LOSS: 0.2687 VAL-ACC: 0.9085
----------
TOTAL-TIME: 1m10s BEST-VAL-ACC: 0.9085
```

è®­ç»ƒ10è½®ï¼Œæ€»ç”¨æ—¶1m10sï¼ŒéªŒè¯é›†æœ€å¤§å‡†ç¡®ç‡0.9085

- ç‰¹å¾æå–

```shell
EPOCH: 01/10 LR: 0.0010 LOSS: 0.7262 ACC: 0.6598  VAL-LOSS: 0.2515 VAL-ACC: 0.9085
EPOCH: 02/10 LR: 0.0010 LOSS: 0.5294 ACC: 0.7951  VAL-LOSS: 0.3064 VAL-ACC: 0.8627
EPOCH: 03/10 LR: 0.0010 LOSS: 0.5121 ACC: 0.7746  VAL-LOSS: 0.1943 VAL-ACC: 0.9346
EPOCH: 04/10 LR: 0.0010 LOSS: 0.4977 ACC: 0.7992  VAL-LOSS: 0.1751 VAL-ACC: 0.9477
EPOCH: 05/10 LR: 0.0010 LOSS: 0.5162 ACC: 0.7992  VAL-LOSS: 0.1880 VAL-ACC: 0.9412
EPOCH: 06/10 LR: 0.0001 LOSS: 0.4928 ACC: 0.7869  VAL-LOSS: 0.1695 VAL-ACC: 0.9542
EPOCH: 07/10 LR: 0.0001 LOSS: 0.3889 ACC: 0.8156  VAL-LOSS: 0.1952 VAL-ACC: 0.9412
EPOCH: 08/10 LR: 0.0001 LOSS: 0.3160 ACC: 0.8648  VAL-LOSS: 0.1897 VAL-ACC: 0.9412
EPOCH: 09/10 LR: 0.0001 LOSS: 0.4431 ACC: 0.7828  VAL-LOSS: 0.1689 VAL-ACC: 0.9542
EPOCH: 10/10 LR: 0.0001 LOSS: 0.2999 ACC: 0.8770  VAL-LOSS: 0.2250 VAL-ACC: 0.9346
----------
TOTAL-TIME: 0m45s BEST-VAL-ACC: 0.9542
```

è®­ç»ƒ10è½®ï¼Œæ€»ç”¨æ—¶0m46sï¼ŒéªŒè¯é›†æœ€å¤§å‡†ç¡®ç‡0.9542

ä»å¤´è®­ç»ƒï¼ˆä¸ä½¿ç”¨è¿ç§»å­¦ä¹ ï¼Œå°†å‚æ•°å¾®è°ƒçš„ä»£ç pretrainedè®¾ç½®ä¸ºFalseå³å¯ï¼‰

```shell
EPOCH: 01/10 LR: 0.0010 LOSS: 0.7462 ACC: 0.5574  VAL-LOSS: 0.7228 VAL-ACC: 0.5556
EPOCH: 02/10 LR: 0.0010 LOSS: 0.7729 ACC: 0.5984  VAL-LOSS: 0.8003 VAL-ACC: 0.6209
EPOCH: 03/10 LR: 0.0010 LOSS: 0.8077 ACC: 0.5943  VAL-LOSS: 0.7597 VAL-ACC: 0.5163
EPOCH: 04/10 LR: 0.0010 LOSS: 0.7494 ACC: 0.5820  VAL-LOSS: 0.6755 VAL-ACC: 0.5556
EPOCH: 05/10 LR: 0.0010 LOSS: 0.7517 ACC: 0.6148  VAL-LOSS: 0.6289 VAL-ACC: 0.6144
EPOCH: 06/10 LR: 0.0001 LOSS: 0.6333 ACC: 0.6475  VAL-LOSS: 0.5897 VAL-ACC: 0.6797
EPOCH: 07/10 LR: 0.0001 LOSS: 0.6007 ACC: 0.6967  VAL-LOSS: 0.6266 VAL-ACC: 0.6667
EPOCH: 08/10 LR: 0.0001 LOSS: 0.6316 ACC: 0.6516  VAL-LOSS: 0.6142 VAL-ACC: 0.6797
EPOCH: 09/10 LR: 0.0001 LOSS: 0.6109 ACC: 0.6639  VAL-LOSS: 0.5907 VAL-ACC: 0.6928
EPOCH: 10/10 LR: 0.0001 LOSS: 0.5951 ACC: 0.6844  VAL-LOSS: 0.5939 VAL-ACC: 0.6928
----------
TOTAL-TIME: 1m11s BEST-VAL-ACC: 0.6928
```

è®­ç»ƒ10è½®ï¼Œæ€»ç”¨æ—¶1m11sï¼ŒéªŒè¯é›†æœ€å¤§å‡†ç¡®ç‡0.6928

> å¯¹æ¯”å‘ç°ï¼Œä½¿ç”¨è¿ç§»å­¦ä¹ èµ·ç‚¹æ›´é«˜ï¼Œæ”¶æ•›æ›´å¿«ã€‚å…¶ä¸­ç‰¹å¾æå–æ€»ç”¨æ—¶æ›´çŸ­ï¼Œå‡†ç¡®ç‡æ›´é«˜ã€‚è¿™ä¸ªç»“æœæ˜¯é¢„æ–™ä¹‹ä¸­çš„ï¼Œåœ¨è¿ç§»æ–¹æ³•çš„é€‰æ‹©ä¸­ï¼Œæˆ‘ä»¬çŸ¥é“å¯¹äºæ•°æ®é›†è¾ƒå°ï¼Œä¸”ä¸åŸå§‹æ•°æ®é›†ç›¸ä¼¼åº¦é«˜æ—¶ï¼Œé€‰æ‹©ç‰¹å¾æå–çš„æ–¹æ³•ä¼šæ›´å¥½ã€‚

### éªŒè¯ç»“æœå¯è§†åŒ–
```python
def visualize_model(model):
    model.eval()
    with torch.no_grad():
        inputs, labels = next(iter(dataloaders['val']))
        inputs = inputs.to(device)
        labels = labels.to(device)

        outputs = model(inputs)
        preds = outputs.argmax(1)

        plt.figure(figsize=(9, 9))
        for i in range(inputs.size(0)):
            plt.subplot(2,2,i+1)
            plt.axis('off')
            plt.title(f'pred: {class_names[preds[i]]}|true: {class_names[labels[i]]}')
            im = no_normalize(inputs[i].cpu())
            plt.imshow(im)
        plt.savefig('train.jpg')
		plt.show()
```
![image](https://user-images.githubusercontent.com/29084184/119220106-60f34980-bb1b-11eb-99c1-f142f099b78c.png)


### ä¿å­˜æ¨¡å‹
æ›´è¯¦ç»†çš„pytorchä¿å­˜å’ŒåŠ è½½æ¨¡å‹çš„æ–¹æ³•å¯ä»¥çœ‹æˆ‘çš„è¿™ç¯‡æ–‡ç« 
```
torch.save(model_conv.state_dict(), 'model.pt')
```
### åŠ è½½æ¨¡å‹

æ›´è¯¦ç»†çš„pytorchä¿å­˜å’ŒåŠ è½½æ¨¡å‹çš„æ–¹æ³•å¯ä»¥çœ‹æˆ‘çš„è¿™ç¯‡æ–‡ç« 
```
device = torch.device('cpu')
model = models.resnet18(pretrained=False)
num_ftrs = model.fc.in_features
model.fc = nn.Linear(num_ftrs, len(class_names))
model.load_state_dict(torch.load('model.pt', map_location=device))
```
### æµ‹è¯•æ¨¡å‹
ç™¾åº¦æˆ–å¿…åº”å›¾ç‰‡ä¸­éšä¾¿æ‰¾å‡ å¼ å¼ èš‚èšå’Œèœœèœ‚çš„å›¾ç‰‡ï¼Œæˆ–è€…ç”¨æ‰‹æœºæ‹å‡ å¼ ç…§ç‰‡ä¹Ÿè¡Œã€‚ç”¨ä¸Šä¸€æ­¥åŠ è½½çš„æ¨¡å‹æµ‹è¯•ä¸€ä¸‹åˆ†ç±»çš„æ•ˆæœã€‚

![image](https://user-images.githubusercontent.com/29084184/119220112-651f6700-bb1b-11eb-89e1-09d4e3dd1eee.png)

### å®Œæ•´ä»£ç 

ğŸ“ <a href="https://github.com/Charmve/computer-vision-in-action/tree/main/code/chapter15_è¿ç§»å­¦ä¹ :èš‚èšå’Œèœœèœ‚çš„åˆ†ç±»é—®é¢˜">``code/chapter15_è¿ç§»å­¦ä¹ :èš‚èšå’Œèœœèœ‚çš„åˆ†ç±»é—®é¢˜/``</a>

<table class="tfo-notebook-buttons\" align="left\">
<td>
  <a target="_blank" href="colab.research.google.com/github/Charmve/computer-vision-in-action/blob/master/notebooks/17_TL-ants-bees-classification.ipynb">
  <img src="https://www.tensorflow.org/images/colab_logo_32px.png\">
  Run in Google Colab</a>
</td>
<td>
  <a target="_blank\" href="https://github.com/Charmve/computer-vision-in-action/tree/main/code/chapter15_è¿ç§»å­¦ä¹ :èš‚èšå’Œèœœèœ‚çš„åˆ†ç±»é—®é¢˜/">
  <img src="https://www.tensorflow.org/images/GitHub-Mark-32px.png\">
  View source on GitHub</a>
</td>
</table>
